{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B8R4bzpQVCH0"
   },
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GVuRWX7iVkR4"
   },
   "source": [
    "Here, we're going to establish a  baseline model for our audio classification model. The baseline will use, as defined in the \"models.py\" class, will be a 2 layer neural network, with a hidden layer size of 20. \n",
    "\n",
    "There is a dropout layer with a 0.75 just after the hidden layer and before the output softmax layer. \n",
    "\n",
    "We use a standard scaler because our features are on different scales (look at data prep for more info), which will ensure we get more effecient/effective error minimization.\n",
    "\n",
    "Afterwards, we will expand this baseline by adding more hidden layers and the necessary model regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bnhb1omAafOU"
   },
   "source": [
    "We're going to see how this baseline performs with 3 different feature selection methods, so we don't have to try out these permutations later (it's difficult to integrate all these different feature selection methods with sklearn random search). So, we will simply choose the feature selection method that gives the best validation results on the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1592,
     "status": "ok",
     "timestamp": 1571771995994,
     "user": {
      "displayName": "Raj Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCPoOOggLiJ4-1xvJydMxpj_sP_cdeh5gJn9JI=s64",
      "userId": "16134859439101082089"
     },
     "user_tz": 240
    },
    "id": "_88DR00ybPzk",
    "outputId": "a34fa38d-b3d2-4e5d-cf46-adca7cf0fb09"
   },
   "outputs": [],
   "source": [
    "# so we have access to the Google Drive filesystem\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4044,
     "status": "ok",
     "timestamp": 1571771998452,
     "user": {
      "displayName": "Raj Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCPoOOggLiJ4-1xvJydMxpj_sP_cdeh5gJn9JI=s64",
      "userId": "16134859439101082089"
     },
     "user_tz": 240
    },
    "id": "aTAlCMIFU_I2",
    "outputId": "9bcee560-46cf-4a50-8920-ce2ed06f8f8d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# necessary imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# so we can access local modules within Colab\n",
    "#os.chdir('/content/drive/My Drive/auto-age-detector-model')\n",
    "\n",
    "# feature selection defined functions\n",
    "from feature_selection import lasso_feature_selection\n",
    "from feature_selection import tree_based_feature_selection\n",
    "from feature_selection import chi_squared_feature_selection\n",
    "from feature_selection import pca_feature_selection\n",
    "\n",
    "# baseline model creation\n",
    "from models import baseline_model\n",
    "\n",
    "# for feature scaling\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BDXeEAWbccAe"
   },
   "source": [
    "Here, we import the training data, omitting feature unneccessary for our model. Then we split it into our inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U-fHrlTicU5p"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('C:\\\\Users\\\\gotty\\\\Desktop\\\\project\\\\models\\\\sample.csv').drop(columns=['Unnamed: 0','path'])\n",
    "# drop any null values we may have forgotten\n",
    "df_train = df_train.dropna(how='any',axis=0)\n",
    "X_train = df_train.drop(columns=['age'],axis=1)\n",
    "y_train = df_train['age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XfEt7i-sd0iZ"
   },
   "source": [
    "We one hot encode the outputs so we can build a multiclass classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GrC4d1Yhd9gS"
   },
   "outputs": [],
   "source": [
    "replaced = {'teens':0,'twenties':1,'thirties':2,'fourties':3,'fifties':4,\n",
    "            'sixties':5,'seventies':6,'eighties':7,'nineties':8}\n",
    "\n",
    "# https://stackoverflow.com/questions/29831489/convert-array-of-indices-to-1-hot-encoded-numpy-array\n",
    "\n",
    "# need to put one hot encoded in keras model\n",
    "y_train_ohe = y_train.replace(replaced).astype(int)\n",
    "from numpy import array\n",
    "y_train_ohe = array(y_train_ohe)\n",
    "y_train_ohe = np.eye(np.max(y_train_ohe)+1)[y_train_ohe]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "135FaqjMez8d"
   },
   "source": [
    "Now we're going to fit a model with different feature selection methods.\n",
    "\n",
    "We're going to use a validation split of 0.2, 15 epochs, and a batch size of 32 for these initial baselines. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6ZKtU3dFk6uu"
   },
   "source": [
    "## Baseline with L1 feature selection - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 156006,
     "status": "ok",
     "timestamp": 1571772150432,
     "user": {
      "displayName": "Raj Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCPoOOggLiJ4-1xvJydMxpj_sP_cdeh5gJn9JI=s64",
      "userId": "16134859439101082089"
     },
     "user_tz": 240
    },
    "id": "My4YWH-pk5q6",
    "outputId": "d6aa21a0-065b-4006-e74c-1bd0dc6a13ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced to 0 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gotty\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\gotty\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\gotty\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\base.py:79: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-0cebf86fb821>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmodel_l1_log_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbaseline_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m model_l1_log_reg.fit(X_train_l1_log_reg,y_train_ohe,batch_size=32,\n\u001b[1;32m---> 15\u001b[1;33m                     validation_split=0.15,epochs=10)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[1;31m# to match the value shapes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_set_inputs\u001b[1;34m(self, inputs, outputs, training)\u001b[0m\n\u001b[0;32m    414\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_input_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    504\u001b[0m             if all([s is not None\n\u001b[0;32m    505\u001b[0m                     for s in to_list(input_shape)]):\n\u001b[1;32m--> 506\u001b[1;33m                 \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    915\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m         \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m         \u001b[0moutput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# feature scaling before to help with convergence\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_l1_log_reg = scaler.transform(X_train)\n",
    "\n",
    "X_train_l1_log_reg,data_transformer = lasso_feature_selection(X_train_l1_log_reg,\n",
    "                                                              y_train,\n",
    "                                                              model='logreg')\n",
    "\n",
    "print(f'Reduced to {X_train_l1_log_reg.shape[1]} features.')\n",
    "\n",
    "\n",
    "model_l1_log_reg = baseline_model(4)\n",
    "model_l1_log_reg.fit(X_train_l1_log_reg,y_train_ohe,batch_size=32,\n",
    "                    validation_split=0.15,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m8-gFfGglXHM"
   },
   "source": [
    "## Baseline with tree-based feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 290838,
     "status": "ok",
     "timestamp": 1571772285269,
     "user": {
      "displayName": "Raj Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCPoOOggLiJ4-1xvJydMxpj_sP_cdeh5gJn9JI=s64",
      "userId": "16134859439101082089"
     },
     "user_tz": 240
    },
    "id": "gi6vVOCAoUfq",
    "outputId": "0196ab6c-fcda-424f-a1aa-bc76e51ea903"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced to 63 features.\n",
      "WARNING:tensorflow:From C:\\Users\\gotty\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 26 samples, validate on 5 samples\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 2.0873 - accuracy: 0.1923 - val_loss: 2.2998 - val_accuracy: 0.4000\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 0s 308us/step - loss: 2.3462 - accuracy: 0.1923 - val_loss: 2.2798 - val_accuracy: 0.4000\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 0s 346us/step - loss: 2.4193 - accuracy: 0.1923 - val_loss: 2.2629 - val_accuracy: 0.4000\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 0s 308us/step - loss: 2.3242 - accuracy: 0.2308 - val_loss: 2.2438 - val_accuracy: 0.4000\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 2.4264 - accuracy: 0.1538 - val_loss: 2.2255 - val_accuracy: 0.4000\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 0s 423us/step - loss: 2.4322 - accuracy: 0.1923 - val_loss: 2.2061 - val_accuracy: 0.4000\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 0s 346us/step - loss: 1.9492 - accuracy: 0.2692 - val_loss: 2.1871 - val_accuracy: 0.4000\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 0s 385us/step - loss: 1.8859 - accuracy: 0.2692 - val_loss: 2.1691 - val_accuracy: 0.4000\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 0s 308us/step - loss: 1.9903 - accuracy: 0.3077 - val_loss: 2.1520 - val_accuracy: 0.4000\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 0s 269us/step - loss: 2.0046 - accuracy: 0.3462 - val_loss: 2.1337 - val_accuracy: 0.4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1fc23190608>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tree,data_transformer = tree_based_feature_selection(X_train,y_train,\n",
    "                                                        n_estimators=75)\n",
    "\n",
    "print(f'Reduced to {X_train_tree.shape[1]} features.')\n",
    "# feature scaling after\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_tree)\n",
    "X_train_tree = scaler.transform(X_train_tree)\n",
    "\n",
    "model_tree = baseline_model(4)\n",
    "model_tree.fit(X_train_tree,y_train_ohe,batch_size=32,\n",
    "                    validation_split=0.15,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8_i40YuapBet"
   },
   "source": [
    "## Baseline with chi_squared_based_feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M0r1WEunqE3k"
   },
   "source": [
    "Try with 80 best features first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 393854,
     "status": "ok",
     "timestamp": 1571772388290,
     "user": {
      "displayName": "Raj Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCPoOOggLiJ4-1xvJydMxpj_sP_cdeh5gJn9JI=s64",
      "userId": "16134859439101082089"
     },
     "user_tz": 240
    },
    "id": "-IBXuJD1oy8W",
    "outputId": "35aa6e27-aace-4cfa-c2c5-31fb2b4c1a31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced to 80 features.\n",
      "Train on 26 samples, validate on 5 samples\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.4739 - accuracy: 0.5769 - val_loss: 1.3068 - val_accuracy: 0.4000\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 0s 423us/step - loss: 1.3077 - accuracy: 0.5385 - val_loss: 1.3003 - val_accuracy: 0.4000\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 0s 423us/step - loss: 1.3081 - accuracy: 0.4615 - val_loss: 1.2984 - val_accuracy: 0.4000\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 0s 385us/step - loss: 1.5157 - accuracy: 0.4231 - val_loss: 1.2989 - val_accuracy: 0.4000\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 0s 308us/step - loss: 1.4723 - accuracy: 0.3462 - val_loss: 1.3007 - val_accuracy: 0.4000\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 0s 461us/step - loss: 1.2538 - accuracy: 0.5000 - val_loss: 1.3045 - val_accuracy: 0.4000\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 0s 423us/step - loss: 1.3799 - accuracy: 0.3462 - val_loss: 1.3058 - val_accuracy: 0.4000\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 0s 423us/step - loss: 1.2062 - accuracy: 0.5385 - val_loss: 1.3079 - val_accuracy: 0.4000\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 0s 385us/step - loss: 1.1334 - accuracy: 0.5385 - val_loss: 1.3111 - val_accuracy: 0.4000\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 0s 385us/step - loss: 1.0717 - accuracy: 0.6154 - val_loss: 1.3149 - val_accuracy: 0.4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1fc1039bc88>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_chi2_80,data_transformer = chi_squared_feature_selection(X_train,\n",
    "                                                              y_train)\n",
    "\n",
    "print(f'Reduced to {X_train_chi2_80.shape[1]} features.')\n",
    "# feature scaling after\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_chi2_80)\n",
    "X_train_chi2_80 = scaler.transform(X_train_chi2_80)\n",
    "\n",
    "model_chi2_80 = baseline_model(4)\n",
    "model_chi2_80.fit(X_train_chi2_80,y_train_ohe,batch_size=32,\n",
    "                  validation_split=0.15,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oBErDh8ZryQf"
   },
   "source": [
    "Now try with 50 features to see if performance improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 496434,
     "status": "ok",
     "timestamp": 1571772490874,
     "user": {
      "displayName": "Raj Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCPoOOggLiJ4-1xvJydMxpj_sP_cdeh5gJn9JI=s64",
      "userId": "16134859439101082089"
     },
     "user_tz": 240
    },
    "id": "goyC20q0rPXD",
    "outputId": "3b0ed17f-1621-480d-b558-7fc8e0a7ed05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced to 50 features.\n",
      "Train on 26 samples, validate on 5 samples\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.5877 - accuracy: 0.2308 - val_loss: 2.2611 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 0s 308us/step - loss: 1.7008 - accuracy: 0.3077 - val_loss: 2.2378 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 0s 346us/step - loss: 1.4563 - accuracy: 0.3077 - val_loss: 2.2107 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 0s 269us/step - loss: 1.5135 - accuracy: 0.3846 - val_loss: 2.1819 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 0s 385us/step - loss: 1.5354 - accuracy: 0.4231 - val_loss: 2.1520 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 0s 269us/step - loss: 1.5000 - accuracy: 0.3077 - val_loss: 2.1216 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 0s 308us/step - loss: 1.3590 - accuracy: 0.3462 - val_loss: 2.0932 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 0s 308us/step - loss: 1.2778 - accuracy: 0.3846 - val_loss: 2.0642 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 0s 269us/step - loss: 1.4806 - accuracy: 0.3846 - val_loss: 2.0357 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 0s 269us/step - loss: 1.2993 - accuracy: 0.3077 - val_loss: 2.0056 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1fc117be788>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_chi2_50,data_transformer = chi_squared_feature_selection(X_train,\n",
    "                                                              y_train,k=50)\n",
    "\n",
    "print(f'Reduced to {X_train_chi2_50.shape[1]} features.')\n",
    "# feature scaling after\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_chi2_50)\n",
    "X_train_chi2_50 = scaler.transform(X_train_chi2_50)\n",
    "\n",
    "model_chi2_50 = baseline_model(4)\n",
    "model_chi2_50.fit(X_train_chi2_50,y_train_ohe,batch_size=32,\n",
    "                  validation_split=0.15,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BUv5wMhc4TlE"
   },
   "source": [
    "## PCA Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 107408,
     "status": "ok",
     "timestamp": 1571772771781,
     "user": {
      "displayName": "Raj Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCPoOOggLiJ4-1xvJydMxpj_sP_cdeh5gJn9JI=s64",
      "userId": "16134859439101082089"
     },
     "user_tz": 240
    },
    "id": "rsESdq6dz1pC",
    "outputId": "a5d3a202-8b7c-4ada-c8ff-fc7cd26e8136"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26 samples, validate on 5 samples\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.1132 - accuracy: 0.2692 - val_loss: 1.2481 - val_accuracy: 0.4000\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 0s 462us/step - loss: 3.0492 - accuracy: 0.2692 - val_loss: 1.2494 - val_accuracy: 0.4000\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 0s 346us/step - loss: 3.0387 - accuracy: 0.2692 - val_loss: 1.2495 - val_accuracy: 0.4000\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 0s 385us/step - loss: 2.7256 - accuracy: 0.1538 - val_loss: 1.2499 - val_accuracy: 0.4000\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 0s 308us/step - loss: 3.6434 - accuracy: 0.2692 - val_loss: 1.2502 - val_accuracy: 0.4000\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 0s 346us/step - loss: 2.8038 - accuracy: 0.2308 - val_loss: 1.2497 - val_accuracy: 0.4000\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 0s 308us/step - loss: 2.9647 - accuracy: 0.3077 - val_loss: 1.2494 - val_accuracy: 0.4000\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 0s 269us/step - loss: 2.9924 - accuracy: 0.2308 - val_loss: 1.2494 - val_accuracy: 0.4000\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 0s 231us/step - loss: 2.4442 - accuracy: 0.3462 - val_loss: 1.2492 - val_accuracy: 0.4000\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 0s 308us/step - loss: 2.3143 - accuracy: 0.2308 - val_loss: 1.2489 - val_accuracy: 0.4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1fc12d96e88>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature scaling because PCA is bias towards high magnitude features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_pca = scaler.transform(X_train)\n",
    "\n",
    "# get 80 best features\n",
    "X_train_pca,data_transformer = pca_feature_selection(X_train_pca,31)\n",
    "\n",
    "model_pca = baseline_model(4)\n",
    "model_pca.fit(X_train_pca,y_train_ohe,batch_size=32,\n",
    "                  validation_split=0.15,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QhXOwJFh9VLn"
   },
   "source": [
    "We've finished all feature selection methods for our baseline models. Luckily, all baseline models are decreasing training error after each epoch, which verifies that our neural network is fitting to the data.\n",
    "\n",
    "Tree-based feature selection seemed to yield the best results, so we will use this type of feature selection going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BhVskw_78zuO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "baseline-model-final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
